{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2605acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset and Model Save Paths\n",
    "base_path = r\"E:\\UESTC 2024\\Ehtisham Paper\\2016 binary\\Preprocessed_Data\"\n",
    "model_save_path = r\"E:\\UESTC 2024\\Ehtisham Paper\\Model_Weights\\hybrid_model.pth\"\n",
    "\n",
    "# Data Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load Dataset\n",
    "dataset = datasets.ImageFolder(root=base_path, transform=transform)\n",
    "num_classes = len(dataset.classes)\n",
    "\n",
    "# Function to visualize sample images\n",
    "def show_samples(dataset):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    for i in range(5):\n",
    "        img, label = dataset[i]\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(dataset.classes[label])\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "show_samples(dataset)\n",
    "\n",
    "# Channel Attention Module\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=8):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n",
    "        return self.sigmoid(avg_out + max_out)\n",
    "\n",
    "# Spatial Attention Module\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        return self.sigmoid(self.conv(x))\n",
    "\n",
    "# Hybrid Model\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.vgg = models.vgg16(pretrained=True)\n",
    "        \n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "        self.vgg = nn.Sequential(*list(self.vgg.children())[:-2])\n",
    "        \n",
    "        self.ca = ChannelAttention(2048)  # For ResNet50\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        self.ca_vgg = ChannelAttention(512)  # For VGG16\n",
    "        self.sa_vgg = SpatialAttention()\n",
    "        \n",
    "        self.fc = nn.Linear(2048 + 512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        resnet_feat = self.resnet(x)\n",
    "        vgg_feat = self.vgg(x)\n",
    "        \n",
    "        resnet_feat = self.ca(resnet_feat) * resnet_feat\n",
    "        resnet_feat = self.sa(resnet_feat) * resnet_feat\n",
    "        \n",
    "        vgg_feat = self.ca_vgg(vgg_feat) * vgg_feat\n",
    "        vgg_feat = self.sa_vgg(vgg_feat) * vgg_feat\n",
    "        \n",
    "        resnet_feat = torch.flatten(resnet_feat, start_dim=1)\n",
    "        vgg_feat = torch.flatten(vgg_feat, start_dim=1)\n",
    "        \n",
    "        features = torch.cat((resnet_feat, vgg_feat), dim=1)\n",
    "        output = self.fc(features)\n",
    "        return output\n",
    "\n",
    "# Visualizing Model Architecture\n",
    "model = HybridModel(num_classes)\n",
    "print(model)\n",
    "\n",
    "# Training and Evaluation\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "k_folds = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "all_labels = np.array([label for _, label in dataset.imgs])\n",
    "\n",
    "overall_metrics = []\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(all_labels)), all_labels)):\n",
    "    print(f\"Fold {fold+1}/{k_folds}\")\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    \n",
    "    # Evaluate Model\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    auc = roc_auc_score(y_true, y_pred, multi_class='ovr')\n",
    "\n",
    "    overall_metrics.append((acc, precision, recall, f1, auc))\n",
    "\n",
    "print(\"Final Results:\", np.mean(overall_metrics, axis=0))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
