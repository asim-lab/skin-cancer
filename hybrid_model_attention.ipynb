{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e5a1e6e",
   "metadata": {},
   "source": [
    "# Hybrid Model with Attention Mechanism (PyTorch)\n",
    "\n",
    "This notebook implements a hybrid deep learning model combining ResNet50 and VGG16 with attention mechanisms for melanoma detection. The model incorporates channel and spatial attention mechanisms, cross-validation, and proper evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5969cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096466da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset Path\n",
    "data_dir = \"path_to_dataset\"  # Update with the actual path\n",
    "\n",
    "# Data Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load Dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "num_classes = len(dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to visualize sample images\n",
    "def show_samples(dataset):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    for i in range(5):\n",
    "        img, label = dataset[i]\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(dataset.classes[label])\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "show_samples(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Channel Attention Module\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=8):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n",
    "        return self.sigmoid(avg_out + max_out)\n",
    "\n",
    "# Spatial Attention Module\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        return self.sigmoid(self.conv(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ddf590",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hybrid Model\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.vgg = models.vgg16(pretrained=True)\n",
    "        \n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "        self.vgg = nn.Sequential(*list(self.vgg.children())[:-2])\n",
    "        \n",
    "        self.ca = ChannelAttention(2048)  # For ResNet50\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        self.ca_vgg = ChannelAttention(512)  # For VGG16\n",
    "        self.sa_vgg = SpatialAttention()\n",
    "        \n",
    "        self.fc = nn.Linear(2048 + 512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        resnet_feat = self.resnet(x)\n",
    "        vgg_feat = self.vgg(x)\n",
    "        \n",
    "        resnet_feat = self.ca(resnet_feat) * resnet_feat\n",
    "        resnet_feat = self.sa(resnet_feat) * resnet_feat\n",
    "        \n",
    "        vgg_feat = self.ca_vgg(vgg_feat) * vgg_feat\n",
    "        vgg_feat = self.sa_vgg(vgg_feat) * vgg_feat\n",
    "        \n",
    "        resnet_feat = torch.flatten(resnet_feat, start_dim=1)\n",
    "        vgg_feat = torch.flatten(vgg_feat, start_dim=1)\n",
    "        \n",
    "        features = torch.cat((resnet_feat, vgg_feat), dim=1)\n",
    "        output = self.fc(features)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training and Evaluation\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "k_folds = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "all_labels = np.array([label for _, label in dataset.imgs])\n",
    "\n",
    "overall_metrics = []\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(all_labels)), all_labels)):\n",
    "    print(f\"Fold {fold+1}/{k_folds}\")\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "    \n",
    "    model = HybridModel(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Evaluate Model\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    auc = roc_auc_score(y_true, y_pred, multi_class='ovr')\n",
    "    \n",
    "    overall_metrics.append((acc, precision, recall, f1, auc))\n",
    "    print(f\"Fold {fold+1}: Accuracy={acc:.4f}, F1-score={f1:.4f}\")\n",
    "\n",
    "print(\"Final Results:\", np.mean(overall_metrics, axis=0))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
